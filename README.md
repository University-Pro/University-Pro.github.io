# Tang Zhizhe(zztang)(CN:æ±¤è‡³å“²)

> Master of Artificial Intelligence(AI) | Seeking PhD Position in Computer Vision start at 2026 fall (after july) or 2027 spring

ğŸŒ **Info Website:** [https://zztang.anhuiuniversity.top](https://zztang.anhuiuniversity.top) | 
ğŸ’» **Github** [Personal Page Overview](https://github.com/University-Pro) |
ğŸ“§ **Email** zztang@stu.ahu.edu.cn | 
â“‚ï¸ **ORCID** https://orcid.org/0009-0006-9083-8967
âœï¸ **Blog Website** [My Blog](http://8.133.3.212) |
ğŸ“ **Location:** Hefei, Anhui, China |

---

## ğŸ‘‹ About Me

Hello! I am a Master's student at [School of Internet](https://si.ahu.edu.cn/) in [Anhui University](https://www.ahu.edu.cn/), specializing in Deeplearning in Computer Vision. 
My research interests lie in **Computer Vision Processing**, **Medical Image Segmentation(MIS)**, and their applications in autonomous systems.

I am actively pursuing a PhD position in Japan, with a planned start in Fall 2026 or Spring 2027.
To facilitate a smooth transition, I am open to beginning as a research student (ç ”ä¿®ç”Ÿ) for several months to adapt to life in a new cultural and academic environment.
Japan is my preferred destination for doctoral studies compare with other countries in Asia, inspired by its leading advancements and technological innovation. 

I am proficient in **Python**, and **PyTorch**, and have hands-on experience with Deep Learning in Image Segmenation Framework.
I am skilled in surveying upstream research, reproducing state-of-the-art computer vision models in medical image segmentation, and extracting key components for implementation.
I have strong Linux proficiency and am adept at troubleshooting research-related issues via command-line environments.
I also possess foundational knowledge of Docker and have experience with virtualization platforms (such as Proxmox) for managing GPU resources across workstations and servers.
Additionally, I built and maintained an LLM server within my universityâ€™s network, serving over 900 users with access to various open-source models (e.g., Qwen and DeepSeek).
I am also experienced in maintaining and optimizing hardware components (CPU, GPU, memory, networking, PCI-E, etc.) for high-performance deep learning workloads.
For example, I successfully modified my RTX 2080 Ti by replacing its 1GB VRAM chips with 2GB ones, effectively doubling the VRAM to 22GB.

Iâ€™ve included a radar chart below to summarize my technical capabilities:

---

## ğŸ”¬ Research Interests

*   **2D Image:** Real-time, high-fidelity images segmentation in dynamic environments.
*   **3D Images** Utilizing deep learning for novel view synthesis and scene representation
*   **Image in AI4Science** Developing intuitive and safe interaction paradigms for collaborative robots.

---

## ğŸ“ Education

*   **M.S. in School of Internet** (2023 - 2026)
    *   Anhui University, Hefei, Anhui, China
    *   **Thesis1:** "DLKUNet: A Lightweight and Efficient Network With Depthwise Large Kernel for Medical Image Segmentation" | [ğŸ”— Link to PDF/Thesis Repository](ä½ çš„è®ºæ–‡é“¾æ¥)
    *   **Thesis2:** "KANSeg: An efficient medical image segmentation model based on Kolmogorov-Arnold networks for multi-organ segmentation"
    *   **Thesis3:** 
    *   **Advisor:** [Prof. Zhu][ORCID](https://orcid.org/0000-0002-4001-1551)

*   **R.A. in School of Internet** (2022-2023)
    *   Anhui University, Hefei, Anhui, China
    *   

*   **B.E. in Automation** (2018 - 2022)
    *   *Your Undergraduate University*, City, Country
    *   **GPA:** 3.8/4.0

---

## ğŸ› ï¸ Projects

### [é¡¹ç›®1åç§°] | Python, PyTorch, Open3D
**[ğŸ”— Live Demo](ä½ çš„é¡¹ç›®æ¼”ç¤ºé“¾æ¥) | [ğŸ“‚ Code](ä½ çš„é¡¹ç›®ä»£ç ä»“åº“é“¾æ¥)**

*   æè¿°è¿™ä¸ªé¡¹ç›®æ˜¯åšä»€ä¹ˆçš„ï¼Œè§£å†³äº†ä»€ä¹ˆé—®é¢˜ã€‚
*   è¯¦ç»†è¯´æ˜ä½ çš„**è´¡çŒ®**å’Œä½¿ç”¨çš„**æŠ€æœ¯æ–¹æ³•**ï¼ˆä¾‹å¦‚ï¼šImplemented a keyframe-based pose graph optimization module...ï¼‰ã€‚
*   **ç»“æœå¦‚ä½•ï¼Ÿ**ï¼ˆä¾‹å¦‚ï¼šAchieved 20% improvement in trajectory accuracy on the TUM dataset compared to ORB-SLAM3ï¼‰ã€‚

### [é¡¹ç›®2åç§°] | C++, ROS, PCL
**[ğŸ“‚ Code](ä½ çš„é¡¹ç›®ä»£ç ä»“åº“é“¾æ¥)**

*   å¦ä¸€ä¸ªé¡¹ç›®çš„æè¿°ï¼ŒåŒæ ·éµå¾ªä¸Šé¢çš„ç»“æ„ã€‚
*   å¦‚æœé¡¹ç›®æ˜¯ä¸è¯¾ç¨‹ã€è®ºæ–‡æˆ–å®ä¹ ç›¸å…³çš„ï¼Œè¯·æ˜ç¡®æŒ‡å‡ºã€‚

*(å»ºè®®æ”¾ç½®3-4ä¸ªä½ æœ€å¾—æ„ã€æœ€ç›¸å…³çš„é¡¹ç›®ï¼Œå¹¶ç¡®ä¿ä»£ç ä»“åº“æ˜¯æ•´ç†å¥½çš„ã€æœ‰æ–‡æ¡£çš„)*

---

## ğŸ“œ Publications & Preprints

1.  **Zhang, S.**, Li, W., & Chen, Y. (2023). "è®ºæ–‡æ ‡é¢˜". In *Conference on Robot Learning (CoRL)*. **[ğŸ”— Paper Link]**
    *(å¦‚æœå°šæœªå‘è¡¨ï¼Œå¯ä»¥å†™ "Manuscript in Preparation" æˆ– "To be submitted to ICRA 2024")*

---

## ğŸ† Honors & Awards

*   **National Scholarship** (2021) - Ministry of Education, China
*   **First Prize**, National University Robot Competition (2020)

---

## ğŸ“« Let's Connect!

I am always open to discussing research opportunities, collaborations, or any interesting ideas.

*   GitHub: [https://github.com/ä½ çš„ç”¨æˆ·å](https://github.com/ä½ çš„ç”¨æˆ·å)
*   LinkedIn: [https://linkedin.com/in/ä½ çš„ç”¨æˆ·å](https://linkedin.com/in/ä½ çš„ç”¨æˆ·å)
*   Twitter/X: [@ä½ çš„ç”¨æˆ·å](https://twitter.com/ä½ çš„ç”¨æˆ·å) *(å¯é€‰ï¼Œå¦‚æœä½ å¸¸ç”¨çš„è¯)*
*   Email: zhangsan@example.com

---

â­ï¸ *From [ä½ çš„ç”¨æˆ·å](https://github.com/ä½ çš„ç”¨æˆ·å)*
