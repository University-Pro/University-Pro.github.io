# Tang Zhizhe(zztang)(CN:æ±¤è‡³å“²)

[![ä¸­æ–‡æ–‡æ¡£](https://img.shields.io/badge/ä¸­æ–‡-æ–‡æ¡£-blue.svg)](./README_CN.md)
[![Japanese Document](https://img.shields.io/badge/English-Docs-orange.svg)](./README_JP.md)
[![Korean Document](https://img.shields.io/badge/Japanese-Docs-fedcba.svg)](./README_JP.md)

> Master of Artificial Intelligence(AI)  
> Seeking PhD Position start at 2026 Fall or 2027 Spring

ğŸŒ **Info Website:** [https://zztang.anhuiuniversity.top](https://zztang.anhuiuniversity.top)  
ğŸ’» **Github** [https://github.com/University-Pro](https://github.com/University-Pro)  
ğŸ“§ **Email** zztang@stu.ahu.edu.cn  
â“‚ï¸ **ORCID** https://orcid.org/0009-0006-9083-8967  
âœï¸ **Blog Website** [My Blog](http://8.133.3.212)  
ğŸ“ **Location:** Hefei, Anhui, China

---

## ğŸ‘‹ About Me

Hello! I am a Master's student at [School of Internet](https://si.ahu.edu.cn/) in [Anhui University](https://www.ahu.edu.cn/),specializing in Deeplearning in Computer Vision.  
My research interests lie in **Computer Vision Processing**, **Medical Image Segmentation(MIS)**, and their applications in autonomous systems.


### Personal Feature Plan
I am actively pursuing a PhD position in Japan, with a planned start in Fall 2026 or Spring 2027.  
To facilitate a smooth transition, I am open to beginning as a research student (ç ”ä¿®ç”Ÿ) for several months to adapt to life in a new cultural and academic environment.  
Japan is my preferred destination for doctoral studies compare with other countries in Asia.

### Ability in Language and Academic Skill
I am able to reads and comprehends full English documentation fluently.  
I have achieved a **TOEIC 805** for first time in **Julyâ€¯2025**; currently working toward a **6.5 IELTS** result.  
I am still a beginner of Japanese. 
I am proficient in **Python**, and **PyTorch**, and have hands-on experience with Deep Learning in **Medical Image Segmenation Framework**.  
I am skilled in surveying upstream research, reproducing state-of-the-art models in multi-area, and extracting key components for implementation.  
I have strong **Linux proficiency** and am adept at troubleshooting research-related issues via command-line only environments.  
I also possess foundational knowledge of **Docker** and have experience with **virtualization platforms** (such as Proxmox) for managing GPU resources across workstations and servers for training model.[(Check My Portainer Manager Picture)](./pictures/1.png).  

### Another Skills
Additionally, I built and maintained an LLM (Large Language Model) server within my universityâ€™s network, serving around 900 users with access to various open-source models (e.g., Qwen and DeepSeek).[(Check My Nginx Monitor)](./pictures/2.png).  
I am also experienced in maintaining and optimizing hardware components (CPU, GPU, memory, networking, PCI-E, etc.) for high-performance deep learning workloads.  
For example, I successfully modified my RTX 2080 Ti by replacing its 1GB VRAM chips with 2GB ones, effectively doubling the VRAM to 22GB.[(Check The Pics of My GPU)](./pictures/1.jpg).  

### Summary
Iâ€™ve included a radar chart below to summarize my technical capabilities:  


![Radar Chat](pictures/3.png)
---

## ğŸ”¬ Research Interests

*   **2D/3D Images Segmentation/Classificationn:** Real-time, high-fidelity images segmentation/classification in dynamic environments.
*   **Image in interdisciplinary:** Use Deeplearning to process(Segmentation/Classification...) images from interdisciplinary.
---

## ğŸ“ Education

*   **M.S. in School of Internet** (2023 - 2026)
    *   Anhui University, Hefei, Anhui, China
    *   **Thesis1:** "DLKUNet: A Lightweight and Efficient Network With Depthwise Large Kernel for Medical Image Segmentation" | [ğŸ”— Link to PDF/Thesis Repository](https://github.com/University-Pro/DLKUNet)
    *   **Thesis2:** "KANSeg: An efficient medical image segmentation model based on Kolmogorov-Arnold networks for multi-organ segmentation" | [ğŸ”— Link to PDF/Thesis Repository](https://github.com/University-Pro/KANSeg)
    *   **Thesis3:** ""
    *   **GPA:** 3.85
    *   **Advisor:** [Prof. Zhu] [ORCID](https://orcid.org/0000-0002-4001-1551)

*   **R.A. in School of Internet** (2022-2023)
    *   Anhui University, Hefei, Anhui, China
    *   Majoy: Maintain

*   **B.E. in Automation** (2018 - 2022)
    *   *Your Undergraduate University*, City, Country
    *   **GPA:** 3.8/4.0

---

## ğŸ› ï¸ Projects

### [é¡¹ç›®1åç§°] | Python, PyTorch, Open3D
**[ğŸ”— Live Demo](ä½ çš„é¡¹ç›®æ¼”ç¤ºé“¾æ¥) | [ğŸ“‚ Code](ä½ çš„é¡¹ç›®ä»£ç ä»“åº“é“¾æ¥)**

*   æè¿°è¿™ä¸ªé¡¹ç›®æ˜¯åšä»€ä¹ˆçš„ï¼Œè§£å†³äº†ä»€ä¹ˆé—®é¢˜ã€‚
*   è¯¦ç»†è¯´æ˜ä½ çš„**è´¡çŒ®**å’Œä½¿ç”¨çš„**æŠ€æœ¯æ–¹æ³•**ï¼ˆä¾‹å¦‚ï¼šImplemented a keyframe-based pose graph optimization module...ï¼‰ã€‚
*   **ç»“æœå¦‚ä½•ï¼Ÿ**ï¼ˆä¾‹å¦‚ï¼šAchieved 20% improvement in trajectory accuracy on the TUM dataset compared to ORB-SLAM3ï¼‰ã€‚

### [é¡¹ç›®2åç§°] | C++, ROS, PCL
**[ğŸ“‚ Code](ä½ çš„é¡¹ç›®ä»£ç ä»“åº“é“¾æ¥)**

*   å¦ä¸€ä¸ªé¡¹ç›®çš„æè¿°ï¼ŒåŒæ ·éµå¾ªä¸Šé¢çš„ç»“æ„ã€‚
*   å¦‚æœé¡¹ç›®æ˜¯ä¸è¯¾ç¨‹ã€è®ºæ–‡æˆ–å®ä¹ ç›¸å…³çš„ï¼Œè¯·æ˜ç¡®æŒ‡å‡ºã€‚

*(å»ºè®®æ”¾ç½®3-4ä¸ªä½ æœ€å¾—æ„ã€æœ€ç›¸å…³çš„é¡¹ç›®ï¼Œå¹¶ç¡®ä¿ä»£ç ä»“åº“æ˜¯æ•´ç†å¥½çš„ã€æœ‰æ–‡æ¡£çš„)*

---

## ğŸ“œ Publications & Preprints

1.  **Zhang, S.**, Li, W., & Chen, Y. (2023). "è®ºæ–‡æ ‡é¢˜". In *Conference on Robot Learning (CoRL)*. **[ğŸ”— Paper Link]**
    *(å¦‚æœå°šæœªå‘è¡¨ï¼Œå¯ä»¥å†™ "Manuscript in Preparation" æˆ– "To be submitted to ICRA 2024")*

---

## ğŸ† Honors & Awards

*   **National Scholarship** (2021) - Ministry of Education, China
*   **First Prize**, National University Robot Competition (2020)

---

## ğŸ“« Let's Connect!

I am always open to discussing research opportunities, collaborations, or any interesting ideas.

*   GitHub: [https://github.com/ä½ çš„ç”¨æˆ·å](https://github.com/ä½ çš„ç”¨æˆ·å)
*   LinkedIn: [https://linkedin.com/in/ä½ çš„ç”¨æˆ·å](https://linkedin.com/in/ä½ çš„ç”¨æˆ·å)
*   Twitter/X: [@ä½ çš„ç”¨æˆ·å](https://twitter.com/ä½ çš„ç”¨æˆ·å) *(å¯é€‰ï¼Œå¦‚æœä½ å¸¸ç”¨çš„è¯)*
*   Email: zhangsan@example.com

---

â­ï¸ *From [ä½ çš„ç”¨æˆ·å](https://github.com/ä½ çš„ç”¨æˆ·å)*
